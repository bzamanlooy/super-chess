{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02944396",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885205de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from pdb import set_trace\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9652bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from degree_freedom_queen import *\n",
    "from degree_freedom_king1 import *\n",
    "from degree_freedom_king2 import *\n",
    "from generate_game import *\n",
    "from Chess_env import *\n",
    "\n",
    "\n",
    "size_board = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec28399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bceca7c",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You can find the environment in the file Chess_env, which contains the class Chess_env. To define an object, you need to provide the board size considered as input. In our example, size_board=4. \n",
    "Chess_env is composed by the following methods:\n",
    "\n",
    "1. Initialise_game. The method initialises an episode by placing the three pieces considered (Agent's king and queen, enemy's king) in the chess board. The outputs of the method are described below in order.\n",
    "\n",
    "     S $\\;$ A matrix representing the board locations filled with 4 numbers: 0, no piece in that position; 1, location of the \n",
    "     agent's king; 2 location of the queen; 3 location of the enemy king.\n",
    "     \n",
    "     X $\\;$ The features, that is the input to the neural network. See the assignment for more information regarding the            definition of the features adopted. To personalise this, go into the Features method of the class Chess_env() and change        accordingly.\n",
    "     \n",
    "     allowed_a $\\;$ The allowed actions that the agent can make. The agent is moving a king, with a total number of 8                possible actions, and a queen, with a total number of $(board_{size}-1)\\times 8$ actions. The total number of possible actions correspond      to the sum of the two, but not all actions are allowed in a given position (movements to locations outside the borders or      against chess rules). Thus, the variable allowed_a is a vector that is one (zero) for an action that the agent can (can't)      make. Be careful, apply the policy considered on the actions that are allowed only.\n",
    "     \n",
    "\n",
    "2. OneStep. The method performs a one step update of the system. Given as input the action selected by the agent, it updates the chess board by performing that action and the response of the enemy king (which is a random allowed action in the settings considered). The first three outputs are the same as for the Initialise_game method, but the variables are computed for the position reached after the update of the system. The fourth and fifth outputs are:\n",
    "\n",
    "     R $\\;$ The reward. To change this, look at the OneStep method of the class where the rewards are set.\n",
    "     \n",
    "     Done $\\;$ A variable that is 1 if the episode has ended (checkmate or draw).\n",
    "     \n",
    "     \n",
    "3. Features. Given the chessboard position, the method computes the features.\n",
    "\n",
    "This information and a quick analysis of the class should be all you need to get going. The other functions that the class exploits are uncommented and constitute an example on how not to write a python code. You can take a look at them if you want, but it is not necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9593a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE THE ENVIRONMENT\n",
    "\n",
    "env=Chess_Env(size_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc05bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRINT 5 STEPS OF AN EPISODE CONSIDERING A RANDOM AGENT\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()                       # INTIALISE GAME\n",
    "\n",
    "print(S)                                                  # PRINT CHESS BOARD (SEE THE DESCRIPTION ABOVE)\n",
    "\n",
    "print('check? ',env.check)                                # PRINT VARIABLE THAT TELLS IF ENEMY KING IS IN CHECK (1) OR NOT (0)\n",
    "print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))    # PRINT THE NUMBER OF LOCATIONS THAT THE ENEMY KING CAN MOVE TO\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    a,_=np.where(allowed_a==1)                  # FIND WHAT THE ALLOWED ACTIONS ARE\n",
    "    a_agent=np.random.permutation(a)[0]         # MAKE A RANDOM ACTION\n",
    "\n",
    "#     set_trace()\n",
    "    S,X,allowed_a,R,Done=env.OneStep(a_agent)   # UPDATE THE ENVIRONMENT\n",
    "    \n",
    "    \n",
    "    ## PRINT CHESS BOARD AND VARIABLES\n",
    "    print('')\n",
    "    print(S)\n",
    "    print(R,'', Done)\n",
    "    print('check? ',env.check)\n",
    "    print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))\n",
    "    \n",
    "    \n",
    "    # TERMINATE THE EPISODE IF Done=True (DRAW OR CHECKMATE)\n",
    "    if Done:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM N_episodes=1000 EPISODES MAKING RANDOM ACTIONS AND COMPUTE THE AVERAGE REWARD AND NUMBER OF MOVES \n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_episodes=1000\n",
    "\n",
    "# VARIABLES WHERE TO SAVE THE FINAL REWARD IN AN EPISODE AND THE NUMBER OF MOVES \n",
    "R_save_random = np.zeros([N_episodes, 1])\n",
    "N_moves_save_random = np.zeros([N_episodes, 1])\n",
    "\n",
    "for n in range(N_episodes):\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()     # INITIALISE GAME\n",
    "    Done=0                                  # SET Done=0 AT THE BEGINNING\n",
    "    i=1                                     # COUNTER FOR THE NUMBER OF ACTIONS (MOVES) IN AN EPISODE\n",
    "    \n",
    "    # UNTIL THE EPISODE IS NOT OVER...(Done=0)\n",
    "    while Done==0:\n",
    "        \n",
    "        # SAME AS THE CELL BEFORE, BUT SAVING THE RESULTS WHEN THE EPISODE TERMINATES \n",
    "        \n",
    "        a,_=np.where(allowed_a==1)\n",
    "        a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "        S,X,allowed_a,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        \n",
    "        if Done:\n",
    "            \n",
    "            R_save_random[n]=np.copy(R)\n",
    "            N_moves_save_random[n]=np.copy(i)\n",
    "\n",
    "            break\n",
    "\n",
    "        i=i+1                               # UPDATE THE COUNTER\n",
    "\n",
    "\n",
    "\n",
    "# AS YOU SEE, THE PERFORMANCE OF A RANDOM AGENT ARE NOT GREAT, SINCE THE MAJORITY OF THE POSITIONS END WITH A DRAW \n",
    "# (THE ENEMY KING IS NOT IN CHECK AND CAN'T MOVE)\n",
    "\n",
    "print('Random_Agent, Average reward:',np.mean(R_save_random),'Number of steps: ',np.mean(N_moves_save_random))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebce4c7",
   "metadata": {},
   "source": [
    "## Defining a simple NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f3b8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork: \n",
    "    \n",
    "    def __init__(self, init_type= 'He', layer_type = 'ReLU', optimization_alg = 'Adam', number_of_layers = 1, number_of_neurons_per_layer = [200], adam_beta = 0.9, output_size = 1, input_size = 58):\n",
    "        \n",
    "        self.Ws = []\n",
    "        self.bs = []\n",
    "        self.layer_type = layer_type\n",
    "        self.optimization_alg = optimization_alg\n",
    "        \n",
    "        \n",
    "        \n",
    "        if init_type == 'Xavier':\n",
    "            W1 = np.random.randn(number_of_neurons_per_layer[0], input_size) * np.sqrt(1 / (input_size))  # first layer \n",
    "            self.Ws.append(W1)\n",
    "            for i in range(1, number_of_layers):\n",
    "            \n",
    "                W = np.random.randn(number_of_neurons_per_layer[i], number_of_neurons_per_layer[i-1]) * np.sqrt(1 / (number_of_neurons_per_layer[i-1]))\n",
    "                self.Ws.append(W)\n",
    "                \n",
    "            W_out = np.random.randn(output_size, number_of_neurons_per_layer[-1]) * np.sqrt(1 / (number_of_neurons_per_layer[-1]))\n",
    "            self.Ws.append(W_out)\n",
    "        elif init_type == 'He':\n",
    "            W1 = np.random.randn(number_of_neurons_per_layer[0], input_size) * np.sqrt(2 / (input_size))  # first layer \n",
    "            self.Ws.append(W1)\n",
    "            for i in range(1, number_of_layers):\n",
    "                W = np.random.randn(number_of_neurons_per_layer[i], number_of_neurons_per_layer[i-1]) * np.sqrt(2 / (number_of_neurons_per_layer[i-1]))\n",
    "                self.Ws.append(W)\n",
    "                \n",
    "            W_out = np.random.randn(output_size, number_of_neurons_per_layer[-1]) * np.sqrt(2 / (number_of_neurons_per_layer[-1]))\n",
    "            self.Ws.append(W_out)\n",
    "            \n",
    "            \n",
    "        else: \n",
    "            print('Not Implemented :=(')\n",
    "            \n",
    "\n",
    "        for i in range(number_of_layers): \n",
    "            b = np.zeros((number_of_neurons_per_layer[i],))\n",
    "            self.bs.append(b)\n",
    "        b_out = np.zeros((output_size,))\n",
    "        self.bs.append(b_out)\n",
    "#         set_trace()\n",
    "        \n",
    "        if (optimization_alg == 'Adam'): \n",
    "            self.Adams_per_layer = [] \n",
    "            for i in range(len(self.Ws)): \n",
    "                adam_weights = Adam(Params = self.Ws[i], beta1 = adam_beta)\n",
    "                adam_biases = Adam(Params = self.bs[i], beta1=  adam_beta)\n",
    "                self.Adams_per_layer.append((adam_weights, adam_biases))\n",
    "        \n",
    "        \n",
    "    def forward(self, x0): \n",
    "        \n",
    "        layer_out = x0\n",
    "        for i in range(len(self.Ws) - 1):\n",
    "            layer_out_pre_activation = np.dot(self.Ws[i], layer_out) + self.bs[i]   # calculate Wx + b\n",
    "            layer_out = 1/(1+np.exp(-layer_out_pre_activation))                     # apply sigmoid funciton \n",
    "            \n",
    "        return layer_out_pre_activation  # because the last layer should have no sigmoid! \n",
    "    \n",
    "    def _forward_batch(self, x0s): \n",
    "        outputs = [] \n",
    "        intermediate_outputs_list = [] \n",
    "        \n",
    "        for x0 in x0s:\n",
    "            output, intermediate_outputs = self._forward(x0)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            intermediate_outputs_list.append(intermediate_outputs)\n",
    "        \n",
    "        return outputs, intermediate_outputs_list\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    def _forward(self, x0): \n",
    "        \n",
    "        intermediate_outputs = [] \n",
    "        layer_out = x0\n",
    "        intermediate_outputs.append(layer_out)\n",
    "        \n",
    "        if self.layer_type == 'ReLU': \n",
    "            for i in range(len(self.Ws) - 1):\n",
    "                layer_out_pre_activation = np.dot(self.Ws[i], layer_out) + self.bs[i]   # calculate Wx + b\n",
    "                layer_out = layer_out_pre_activation.copy()\n",
    "                layer_out[layer_out< 0] = 0    # for ReLU: make all positions <0 equal to 0\n",
    "                intermediate_outputs.append(layer_out)\n",
    "                \n",
    "            layer_out = np.dot(self.Ws[-1], layer_out) + self.bs[-1]\n",
    "            intermediate_outputs.append(layer_out)\n",
    "            \n",
    "            return layer_out, intermediate_outputs\n",
    "                \n",
    "                \n",
    "            \n",
    "        else: \n",
    "            print('entering sigmoid part of forward')\n",
    "\n",
    "            for i in range(len(self.Ws) - 1):\n",
    "                layer_out_pre_activation = np.dot(self.Ws[i], layer_out) + self.bs[i]   # calculate Wx + b\n",
    "                layer_out = 1/(1+np.exp(-layer_out_pre_activation))                     # apply sigmoid funciton\n",
    "                intermediate_outputs.append(layer_out)\n",
    "\n",
    "            layer_out = np.dot(self.Ws[-1], layer_out) + self.bs[-1]\n",
    "            intermediate_outputs.append(layer_out)\n",
    "            \n",
    "            return layer_out, intermediate_outputs\n",
    "    \n",
    "    \n",
    "    def backward(self, x0s, outputs, desired_outputs, intermediate_outputs_list): \n",
    "        \n",
    "        \n",
    "        dWs = [np.zeros(shape = self.Ws[i].shape) for i in range(len(self.Ws))]\n",
    "        dbiases = [np.zeros(shape = self.bs[i].shape) for i in range(len(self.bs))]  \n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(len(x0s)): \n",
    "            \n",
    "            output = outputs[j]\n",
    "            desired_output = desired_outputs[j]\n",
    "            intermediate_outputs = intermediate_outputs_list[j]\n",
    "            x0 = x0s[j]\n",
    "            \n",
    "            \n",
    "            error_signal = desired_output - output\n",
    "\n",
    "            if self.layer_type == 'ReLU': \n",
    "                \n",
    "                for i in reversed(range(len(self.Ws))):\n",
    "                    if i == len(self.Ws) - 1:\n",
    "                        delta = error_signal                  # error signal -> L,  delta x input at layer-> Derivative at that layer    :=>    dW = derivative * lr \n",
    "                        \n",
    "                    else: \n",
    "                        intermediate_outputs_copy = intermediate_outputs[i+1].copy()\n",
    "                        intermediate_outputs_copy[intermediate_outputs_copy < 0] = 0 \n",
    "                        intermediate_outputs_copy[intermediate_outputs_copy > 0 ] = 1\n",
    "                        \n",
    "                        delta = intermediate_outputs_copy * error_signal\n",
    "                    \n",
    "#                     set_trace()\n",
    "                    \n",
    "                    dWs[i] = dWs[i] +  np.outer(delta, intermediate_outputs[i])\n",
    "                    dbiases[i] = dbiases[i] + delta\n",
    "                    \n",
    "                    error_signal = np.dot(self.Ws[i].T, delta)     \n",
    "            \n",
    "            else: \n",
    "                print('backward entering sigmoid part!')\n",
    "            \n",
    "                for i in reversed(range(len(self.Ws))):\n",
    "\n",
    "                    if i == len(self.Ws) - 1:\n",
    "    #                     print('last layer!')\n",
    "                        delta = error_signal\n",
    "                    else:\n",
    "                        delta = intermediate_outputs[i+1]*(1-intermediate_outputs[i+1]) * error_signal\n",
    "\n",
    "                    dWs[i] = dWs[i] +  np.outer(delta, intermediate_outputs[i])\n",
    "                    dbiases[i] = dbiases[i] + delta\n",
    "\n",
    "                    error_signal = np.dot(self.Ws[i].T, delta)\n",
    "                \n",
    "        return dWs, dbiases\n",
    "    \n",
    "    def update(self, dWs, dbiases, batch_size, lr): \n",
    "        \n",
    "        for i in range(len(self.Ws)): \n",
    "            self.Ws[i] = self.Ws[i] + (dWs[i] * lr) / batch_size #- (self.Ws[i] * 0.01* lr) / batch_size\n",
    "            self.bs[i] = self.bs[i] + (dbiases[i] * lr) / batch_size\n",
    "            \n",
    "            \n",
    "        \n",
    "    def train(self, x_train, y_train, lr, epochs, batch_size, print_frequency = 10,  shuffle_indexes = True):\n",
    "        \n",
    "        number_of_batches = int(math.floor(len(x_train)/batch_size))  \n",
    "        \n",
    "#         if (optimization_alg == 'Adam'): \n",
    "#             self.Adams_per_layer = [] \n",
    "#             for i in range(len(self.Ws)): \n",
    "#                 adam_weights = Adam(Params = self.Ws[i], beta1 = adam_beta)\n",
    "#                 adam_biases = Adam(Params = self.bs[i], beta1=  adam_beta)\n",
    "#                 self.Adams_per_layer.append((adam_weights, adam_biases))\n",
    "        \n",
    "#         print('---Before training---')\n",
    "#         for j in range(len(self.Ws)):\n",
    "#             print(f'Sum of Ws for layer {j}: {np.sum(np.abs(self.Ws[j]))} and sum of bs: {np.sum(np.abs(self.bs[j]))}')\n",
    "        \n",
    "        for i in range(epochs): \n",
    "            \n",
    "            if shuffle_indexes: \n",
    "                shuffled_idxs = np.random.permutation(x_train.shape[0])\n",
    "            else: \n",
    "                shuffled_idxs = np.array([i for i in range(len(x_train))])\n",
    "                \n",
    "                \n",
    "            for batch in range(0, number_of_batches): \n",
    "                \n",
    "                idxs_current_batch = shuffled_idxs[batch * batch_size : (batch + 1) * batch_size]\n",
    "\n",
    "                X_batch = x_train[idxs_current_batch]\n",
    "                y_batch = y_train[idxs_current_batch]\n",
    "\n",
    "\n",
    "                outputs, intermediate_outputs_list =  self._forward_batch(x0s= X_batch )\n",
    "                dWs, dbiases = self.backward(x0s = X_batch, outputs = outputs, desired_outputs = y_batch,intermediate_outputs_list = intermediate_outputs_list)\n",
    "                \n",
    "                if self.optimization_alg == 'Adam': \n",
    "                    dWs_adam = [] \n",
    "                    dbiases_adam = [] \n",
    "                    for k in range(len(self.Ws)): \n",
    "                        dWs_adam.append(self.Adams_per_layer[k][0].Compute(dWs[k]))\n",
    "                        dbiases_adam.append(self.Adams_per_layer[k][1].Compute(dbiases[k]))\n",
    "                        \n",
    "                    dWs = dWs_adam\n",
    "                    dbiases = dbiases_adam\n",
    "                        \n",
    "\n",
    "                self.update(dWs, dbiases, batch_size, lr)\n",
    "                \n",
    "#             if (i % print_frequency == 0): \n",
    "#                 print(f'Epoch: {i}')\n",
    "#                 for j in range(len(self.Ws)): \n",
    "#                     print(f'sum of abs dWs for layer {j}: {np.sum(np.abs(dWs[j]))} and sum of dbs: {np.sum(np.abs(dbiases[j]))}')\n",
    "#                     print(f'sum of Ws for layer {j}: {np.sum(np.abs(self.Ws[j]))} and sum of bs: {np.sum(np.abs(self.bs[j]))}')\n",
    "\n",
    "\n",
    "#                 y_pred, _ = self._forward_batch(x0s = x_train)\n",
    "#                 print(f'MSE on the training set: { np.square((np.array(y_pred) - np.array(y_train))).sum() / np.array(y_pred).shape[0] }')\n",
    "#                 print(f'MAE on the training set: { np.abs((np.array(y_pred) - np.array(y_train))).sum() / np.array(y_pred).shape[0] }')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98a5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define Adam\n",
    "\n",
    "class Adam:\n",
    "\n",
    "    def __init__(self, Params, beta1):\n",
    "        \n",
    "        N_dim=np.shape(np.shape(Params))[0] # It finds out if the parameters given are in a vector (N_dim=1) or a matrix (N_dim=2)\n",
    "#         set_trace()\n",
    "        print(f'Init adam was called with parameter shape: {Params.shape}')\n",
    "        \n",
    "        # INITIALISATION OF THE MOMENTUMS\n",
    "        if N_dim==1:\n",
    "               \n",
    "            self.N1=np.shape(Params)[0]\n",
    "            \n",
    "            self.mt=np.zeros([self.N1])\n",
    "            self.vt=np.zeros([self.N1])\n",
    "        \n",
    "        if N_dim==2:\n",
    "            \n",
    "            self.N1=np.shape(Params)[0]\n",
    "            self.N2=np.shape(Params)[1]\n",
    "        \n",
    "            self.mt=np.zeros([self.N1,self.N2])\n",
    "            self.vt=np.zeros([self.N1,self.N2])\n",
    "        \n",
    "        # HYPERPARAMETERS OF ADAM\n",
    "        self.beta1=beta1\n",
    "        self.beta2=0.999\n",
    "        \n",
    "        self.epsilon=10**(-8)\n",
    "        \n",
    "        # COUNTER OF THE TRAINING PROCESS\n",
    "        self.counter=0\n",
    "        \n",
    "        \n",
    "    def Compute(self,Grads):\n",
    "        \n",
    "        # Compute the Adam updates by following the scheme above (beginning of the notebook)\n",
    "        \n",
    "        self.counter=self.counter+1\n",
    "        \n",
    "        self.mt=self.beta1*self.mt+(1-self.beta1)*Grads\n",
    "        \n",
    "        self.vt=self.beta2*self.vt+(1-self.beta2)*Grads**2\n",
    "        \n",
    "        mt_n=self.mt/(1-self.beta1**self.counter)\n",
    "        vt_n=self.vt/(1-self.beta2**self.counter)\n",
    "        \n",
    "        New_grads=mt_n/(np.sqrt(vt_n)+self.epsilon)\n",
    "        \n",
    "        return New_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1238e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define RMSProp\n",
    "\n",
    "class RMSProp:\n",
    "\n",
    "    def __init__(self, Params, RMS_beta = 0.9):\n",
    "        \n",
    "        N_dim=np.shape(np.shape(Params))[0] # It finds out if the parameters given are in a vector (N_dim=1) or a matrix (N_dim=2)\n",
    "        \n",
    "        # INITIALISATION OF THE MOMENTUMS\n",
    "        if N_dim==1:\n",
    "               \n",
    "            self.N1=np.shape(Params)[0]\n",
    "            \n",
    "#             self.mt=np.zeros([self.N1])\n",
    "#             self.vt=np.zeros([self.N1])\n",
    "            \n",
    "            self.gs = np.zeros([self.N1])\n",
    "        \n",
    "        if N_dim==2:\n",
    "            \n",
    "            self.N1=np.shape(Params)[0]\n",
    "            self.N2=np.shape(Params)[1]\n",
    "        \n",
    "            self.gs=np.zeros([self.N1,self.N2])\n",
    "        \n",
    "        # HYPERPARAMETERS OF ADAM\n",
    "        self.beta= RMS_beta\n",
    "        \n",
    "        self.epsilon=10**(-8)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def Compute(self,Grads):\n",
    "        \n",
    "        # Compute the RMS updates by following the scheme above (beginning of the notebook)\n",
    "        \n",
    "        \n",
    "        self.gs=self.beta*self.gs + (1-self.beta)* (Grads**2)\n",
    "        \n",
    "        \n",
    "        New_grads= Grads / (np.sqrt(self.gs) + self.epsilon)\n",
    "        \n",
    "        return New_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[i] for i in range(100)])\n",
    "\n",
    "# y_train = np.cos(X_train)\n",
    "\n",
    "y_train = np.square(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5bdd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "our_nn._forward(X_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb7c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "our_nn = NeuralNetwork(number_of_layers= 1, number_of_neurons_per_layer= [100], input_size= 1 )\n",
    "our_nn.train(X_train, y_train, lr = 1e-1, epochs = 5000, batch_size= 20, optimization_alg = 'Adam', adam_beta = 0.9, shuffle_indexes= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d195149",
   "metadata": {},
   "source": [
    "## Testing against a default implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X, y = make_regression(n_samples=200, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "regr = MLPRegressor(random_state=1, max_iter=5000).fit(X_train, y_train.reshape(-1))\n",
    "# regr.predict(X_test[:2])\n",
    "\n",
    "# regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(regr.predict(X_train) - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(random_state=1, max_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfffe21",
   "metadata": {},
   "source": [
    "## SARSA with value approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8f9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE THE EPSILON-GREEDY POLICY\n",
    "def EpsilonGreedy_Policy(Qvalues, allowed_a, epsilon):\n",
    "    \"\"\"\n",
    "    Plays the epsilon greedy policy, but only over the allowed_actions\n",
    "    \"\"\"\n",
    "    \n",
    "    N_a=np.shape(Qvalues)[0]\n",
    "\n",
    "    rand_value=np.random.uniform(0,1)\n",
    "\n",
    "    rand_a=rand_value<epsilon\n",
    "\n",
    "    if rand_a==True:\n",
    "\n",
    "        a=np.random.randint(0,N_a)\n",
    "        \n",
    "        # find the indexes of the allowed_actions \n",
    "        indexes_allowed_actions = np.where(allowed_a > 0)[0]\n",
    "        # choose an action at random, but only from them! \n",
    "        a = np.random.choice(indexes_allowed_actions)\n",
    "\n",
    "    else:\n",
    "        Qvalues_copy = Qvalues.copy()\n",
    "        # ensure that the non-allowed actions aren't played by making them smaller than the max\n",
    "#         set_trace()\n",
    "        Qvalues_copy[allowed_a == 0] = np.min(Qvalues) - 5\n",
    "        \n",
    "        a=np.argmax(Qvalues_copy)\n",
    "            \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece20429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE THE PARAMETERS OF YOUR NEURAL NETWORK AND...\n",
    "# PLEASE CONSIDER TO USE A MASK OF ONE FOR THE ACTION MADE AND ZERO OTHERWISE IF YOU ARE NOT USING VANILLA GRADIENT DESCENT...\n",
    "# WE SUGGEST A NETWORK WITH ONE HIDDEN LAYER WITH SIZE 200. \n",
    "\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_a=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in=np.shape(X)[0]    ## INPUT SIZE\n",
    "N_h=200                ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2     # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.00005      # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.85        # THE DISCOUNT FACTOR\n",
    "eta = 0.0035        # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 100000 # THE NUMBER OF GAMES TO BE PLAYED \n",
    "\n",
    "# SAVING VARIABLES\n",
    "R_save = np.zeros([N_episodes, 1])\n",
    "N_moves_save = np.zeros([N_episodes, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "for n in range(N_episodes):\n",
    "\n",
    "    epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "    Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "    i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "    print(f'Episode number: {n}')            ## REMOVE THIS OF COURSE, WE USED THIS TO CHECK THAT IT WAS RUNNING.  - Glad to hear.\n",
    "    \n",
    "    while Done==0:                           ## START THE EPISODE\n",
    "        \n",
    "        \n",
    "        ## THIS IS A RANDOM AGENT, CHANGE IT...\n",
    "        \n",
    "        a,_=np.where(allowed_a==1)\n",
    "        a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "                \n",
    "        S_next,X_next,allowed_a_next,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "        if Done==1:\n",
    "            \n",
    "            \n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # IF THE EPISODE IS NOT OVER...\n",
    "        else:\n",
    "            \n",
    "            ## ONLY TO PUT SUMETHING\n",
    "            PIPPO=1\n",
    "            \n",
    "            \n",
    "        # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "        S=np.copy(S_next)\n",
    "        X=np.copy(X_next)\n",
    "        allowed_a=np.copy(allowed_a_next)\n",
    "        \n",
    "        i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_a=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in=np.shape(X)[0]    ## INPUT SIZE\n",
    "N_h=200                ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "\n",
    "## INITALISE YOUR NEURAL NETWORK...\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2     # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.00005      # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.85        # THE DISCOUNT FACTOR\n",
    "eta = 0.0035        # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 100000 # THE NUMBER OF GAMES TO BE PLAYED \n",
    "\n",
    "# SAVING VARIABLES\n",
    "R_save = np.zeros([N_episodes, 1])\n",
    "N_moves_save = np.zeros([N_episodes, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b288ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qlearning(N_episodes = 100000, number_of_layers = 1,number_of_neurons_per_layer = [200],size_board = 4, epsilon_0 = 0.2, beta = 0.00005, gamma = 0.85, eta = 0.0035):\n",
    "    \n",
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "    env=Chess_Env(size_board)\n",
    "    \n",
    "    R_save = np.zeros([N_episodes, 1])\n",
    "    N_moves_save = np.zeros([N_episodes, 1])\n",
    "    \n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()  \n",
    "    number_possible_actions=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "    input_size=np.shape(X)[0]  + number_possible_actions  ## INPUT SIZE: the feature vector + a 1-hot encoding of the 32 actions\n",
    "\n",
    "    # line 1 of Q learning (initialize Qhat)\n",
    "    print(f'Before defining the network')\n",
    "    Q_nn = NeuralNetwork(input_size= input_size, number_of_layers= number_of_layers, number_of_neurons_per_layer= number_of_neurons_per_layer, optimization_alg = 'Adam', adam_beta = 0.9, output_size= 1, init_type= 'He')\n",
    "    print(f'After defining it')\n",
    "    \n",
    "    for n in range(N_episodes):\n",
    "\n",
    "        epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "        Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "        i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "\n",
    "        S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "        print(f'Episode number: {n}')            ## REMOVE THIS OF COURSE, WE USED THIS TO CHECK THAT IT WAS RUNNING.  - Glad to hear.\n",
    "\n",
    "        while Done==0:                           ## START THE EPISODE\n",
    "\n",
    "            \n",
    "            \n",
    "            ######\n",
    "            # calculate Qhat for all possible actions\n",
    "            q_hat_predictions = [] \n",
    "            for k in range(number_possible_actions):\n",
    "                action_vector = [0 for j in range(number_possible_actions)]\n",
    "                action_vector[k] = 1\n",
    "                \n",
    "                nn_input = np.append(X, action_vector)\n",
    "                q_hat_action, _  = Q_nn._forward(nn_input)\n",
    "                \n",
    "                q_hat_predictions.append(q_hat_action)\n",
    "                \n",
    "            \n",
    "            q_hat_predictions = np.array(q_hat_predictions)\n",
    "            \n",
    "            \n",
    "            # Choose A from S using policy derived from Q \n",
    "            selected_action = EpsilonGreedy_Policy(Qvalues = q_hat_predictions, allowed_a = allowed_a, epsilon = epsilon_f)\n",
    "            \n",
    "            action_vector = [0 for j in range(number_possible_actions)]\n",
    "            action_vector[selected_action] = 1\n",
    "            X_train = [np.append(X, action_vector)]\n",
    "            X_train = np.array(X_train)\n",
    "            \n",
    "            # Take the selected action \n",
    "            S_next,X_next,allowed_a_next,R,Done=env.OneStep(selected_action)\n",
    "            \n",
    "            \n",
    "            if not Done:\n",
    "                # calculate max_a Qhat(S', a)\n",
    "                q_hat_predictions = [] \n",
    "                for k in range(number_possible_actions):\n",
    "                    action_vector = [0 for j in range(number_possible_actions)]\n",
    "                    action_vector[k] = 1\n",
    "\n",
    "                    nn_input = np.append(X_next, action_vector)\n",
    "#                     print(f'Shape of nn_input at line 67: {nn_input.shape}')\n",
    "#                     print(f'Are we done: {Done}')\n",
    "                    q_hat_action, _  = Q_nn._forward(nn_input)\n",
    "\n",
    "                    q_hat_predictions.append(q_hat_action)  \n",
    "\n",
    "#                 print('---- REACHED LINE 70 ---- ')\n",
    "                q_hat_predictions = np.array(q_hat_predictions)\n",
    "\n",
    "                Q_star_next = q_hat_predictions[EpsilonGreedy_Policy(q_hat_predictions, allowed_a= allowed_a_next, epsilon = 0)]  # find the max Q of state S'\n",
    "            \n",
    "            if Done == 1: \n",
    "                label = R \n",
    "            else:\n",
    "                label = R + gamma * Q_star_next\n",
    "            \n",
    "            # update the parameters of the network\n",
    "            y_train = np.array([label])\n",
    "            Q_nn.train(x_train = X_train, y_train = y_train, lr = eta, epochs = 1, batch_size = 1, print_frequency = 100,  shuffle_indexes = False)\n",
    "#             (self, x_train, y_train, lr, epochs, batch_size, print_frequency = 10, optimization_alg = 'GD', adam_beta = 0.9, shuffle_indexes = True):\n",
    " \n",
    "\n",
    "            ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "            if Done==1:\n",
    "                R_save[n] = R\n",
    "                N_moves_save[n] = i\n",
    "    \n",
    "                break\n",
    "\n",
    "            # IF THE EPISODE IS NOT OVER...\n",
    "            # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "            S=np.copy(S_next)\n",
    "            X=np.copy(X_next)\n",
    "            allowed_a=np.copy(allowed_a_next)\n",
    "\n",
    "            i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "\n",
    "        \n",
    "    return R_save, N_moves_save, Q_nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6591b8aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before defining the network\n",
      "> \u001b[0;32m/var/folders/p9/gfrslbkj44x2fh12xfn7lbth0000gn/T/ipykernel_1102/2860295335.py\u001b[0m(44)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     42 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 44 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moptimization_alg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdams_per_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p9/gfrslbkj44x2fh12xfn7lbth0000gn/T/ipykernel_1102/812773797.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mR_save_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_moves_save_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_nn_adam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQlearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/p9/gfrslbkj44x2fh12xfn7lbth0000gn/T/ipykernel_1102/21767615.py\u001b[0m in \u001b[0;36mQlearning\u001b[0;34m(N_episodes, number_of_layers, number_of_neurons_per_layer, size_board, epsilon_0, beta, gamma, eta)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# line 1 of Q learning (initialize Qhat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Before defining the network'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mQ_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_layers\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnumber_of_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_neurons_per_layer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnumber_of_neurons_per_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimization_alg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_type\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'He'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'After defining it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p9/gfrslbkj44x2fh12xfn7lbth0000gn/T/ipykernel_1102/2860295335.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, init_type, layer_type, optimization_alg, number_of_layers, number_of_neurons_per_layer, adam_beta, output_size, input_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moptimization_alg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdams_per_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p9/gfrslbkj44x2fh12xfn7lbth0000gn/T/ipykernel_1102/2860295335.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, init_type, layer_type, optimization_alg, number_of_layers, number_of_neurons_per_layer, adam_beta, output_size, input_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moptimization_alg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdams_per_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "R_save_adam, N_moves_save_adam, Q_nn_adam = Qlearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db4795d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def exponential_moving_average(x, smoothing_parameter=0.99):\n",
    "    initial_value = 0\n",
    "    x_ema = [x[0]]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        x_ema.append(x_ema[i-1]*(smoothing_parameter) + x[i]*(1-smoothing_parameter))\n",
    "                        \n",
    "    return x_ema[1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R_save_copy = R_save.copy()\n",
    "R_list = list(R_save_copy.flatten())\n",
    "R_list_ema = exponential_moving_average(R_list)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(R_list_ema)\n",
    "plt.xlabel(\"Training Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5477900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exponential_moving_avg(result_array, ylabel = 'Reward', title = 'Exponential Moving Average of Reward Per Game'):\n",
    "    result_array_copy = result_array.copy()\n",
    "    \n",
    "    R_list = list(result_array_copy.flatten())\n",
    "    R_list_ema = exponential_moving_average(R_list)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(R_list_ema)\n",
    "    plt.xlabel(\"Training Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feddfff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_save_copy = R_save.copy()\n",
    "\n",
    "plot_exponential_moving_avg(R_save_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1faaac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_moves_save_copy = N_moves_save.copy()\n",
    "N_moves_list = list(N_moves_save_copy.flatten())\n",
    "N_moves_list_ema = exponential_moving_average(N_moves_list)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(N_moves_list_ema)\n",
    "plt.xlabel(\"Training Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e136a99",
   "metadata": {},
   "source": [
    "### Implementing Double Q learning (Hasselt, 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoubleQlearning(N_episodes = 100000, number_of_layers = 1,number_of_neurons_per_layer = [200],size_board = 4, epsilon_0 = 0.2, beta = 0.00005, gamma = 0.85, eta = 0.0035):\n",
    "    \n",
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "    env=Chess_Env(size_board)\n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    R_save = np.zeros([N_episodes, 1])\n",
    "    N_moves_save = np.zeros([N_episodes, 1])\n",
    "    \n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()  \n",
    "    number_possible_actions=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "    input_size=np.shape(X)[0]  + number_possible_actions  ## INPUT SIZE: the feature vector + a 1-hot encoding of the 32 actions\n",
    "\n",
    "    # initialize both Networks\n",
    "    Q_nn_A = NeuralNetwork(input_size= input_size, number_of_layers= number_of_layers, number_of_neurons_per_layer= number_of_neurons_per_layer, output_size= 1, init_type= 'He')\n",
    "    Q_nn_B = NeuralNetwork(input_size= input_size, number_of_layers= number_of_layers, number_of_neurons_per_layer= number_of_neurons_per_layer, output_size= 1, init_type= 'He')\n",
    "    \n",
    "    for n in range(N_episodes):\n",
    "\n",
    "        epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "        Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "        i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "\n",
    "        S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "        print(f'Episode number: {n}')            ## REMOVE THIS OF COURSE, WE USED THIS TO CHECK THAT IT WAS RUNNING.  - Glad to hear.\n",
    "\n",
    "        while Done==0:                           ## START THE EPISODE\n",
    "\n",
    "            random_number = rng.random()\n",
    "            \n",
    "            ######\n",
    "            # calculate QhatA, QhatB for all possible actions\n",
    "            q_hat_predictions_A = []\n",
    "            q_hat_predictions_B = []\n",
    "            for k in range(number_possible_actions):\n",
    "                action_vector = [0 for j in range(number_possible_actions)]\n",
    "                action_vector[k] = 1\n",
    "                \n",
    "                nn_input = np.append(X, action_vector)\n",
    "                q_hat_action_A, _  = Q_nn_A._forward(nn_input)\n",
    "                q_hat_action_B, _  = Q_nn_B._forward(nn_input)\n",
    "                \n",
    "                q_hat_predictions_A.append(q_hat_action_A)       # at current state S, use both networks to estimate the Q(S, \\cdot) function\n",
    "                q_hat_predictions_B.append(q_hat_action_B)\n",
    "                \n",
    "            \n",
    "            q_hat_predictions_A = np.array(q_hat_predictions_A)\n",
    "            q_hat_predictions_B = np.array(q_hat_predictions_B)\n",
    "            \n",
    "            q_hat_predictions_sum = q_hat_predictions_A + q_hat_predictions_B\n",
    "            \n",
    "            \n",
    "            # Choose A from S using policy derived from Q \n",
    "            selected_action = EpsilonGreedy_Policy(Qvalues = q_hat_predictions_sum, allowed_a = allowed_a, epsilon = epsilon_f)\n",
    "            \n",
    "            action_vector = [0 for j in range(number_possible_actions)]\n",
    "            action_vector[selected_action] = 1\n",
    "            X_train = [np.append(X, action_vector)]\n",
    "            X_train = np.array(X_train)\n",
    "            \n",
    "            # Take the selected action \n",
    "            S_next,X_next,allowed_a_next,R,Done=env.OneStep(selected_action)\n",
    "            \n",
    "            \n",
    "            if not Done:\n",
    "                # calculate max_a Qhat(S', a)\n",
    "                q_hat_predictions_A = []\n",
    "                q_hat_predictions_B = [] \n",
    "                for k in range(number_possible_actions):\n",
    "                    action_vector = [0 for j in range(number_possible_actions)]\n",
    "                    action_vector[k] = 1\n",
    "\n",
    "                    nn_input = np.append(X_next, action_vector)\n",
    "#                     print(f'Shape of nn_input at line 67: {nn_input.shape}')\n",
    "#                     print(f'Are we done: {Done}')\n",
    "                    q_hat_action_A, _  = Q_nn_A._forward(nn_input)\n",
    "                    q_hat_action_B, _  = Q_nn_B._forward(nn_input)\n",
    "\n",
    "                    q_hat_predictions_A.append(q_hat_action_A)  \n",
    "                    q_hat_predictions_B.append(q_hat_action_A)  \n",
    "\n",
    "#                 print('---- REACHED LINE 70 ---- ')\n",
    "                q_hat_predictions_A = np.array(q_hat_predictions_A)\n",
    "                q_hat_predictions_B = np.array(q_hat_predictions_B)\n",
    "\n",
    "                \n",
    "                \n",
    "                if (random_number < 0.5):\n",
    "                    Q_star_next = q_hat_predictions_B[EpsilonGreedy_Policy(q_hat_predictions_A, allowed_a= allowed_a_next, epsilon = 0)]  # Double Q learning: With 1/2 probability, use Q^A to pick optimal action at S', and Q^B to predict its Q value\n",
    "                else: \n",
    "                    Q_star_next = q_hat_predictions_A[EpsilonGreedy_Policy(q_hat_predictions_B, allowed_a= allowed_a_next, epsilon = 0)]  # Double Q learning: With 1/2 probability, use Q^B to pick optimal action at S', and Q^A to predict its Q value\n",
    "            \n",
    "            if Done == 1: \n",
    "                label = R \n",
    "            else:\n",
    "                label = R + gamma * Q_star_next\n",
    "            \n",
    "            # update the parameters of ONE of the 2 networks (the one we used to pick the action)\n",
    "            y_train = np.array([label])\n",
    "            \n",
    "            if (random_number < 0.5):\n",
    "                Q_nn_A.train(x_train = X_train, y_train = y_train, lr = eta, epochs = 1, batch_size = 1, print_frequency = 100, optimization_alg = 'Adam', adam_beta = 0.9, shuffle_indexes = False)\n",
    "                \n",
    "            else: \n",
    "                Q_nn_B.train(x_train = X_train, y_train = y_train, lr = eta, epochs = 1, batch_size = 1, print_frequency = 100, optimization_alg = 'Adam', adam_beta = 0.9, shuffle_indexes = False)\n",
    "\n",
    "            ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "            if Done==1:\n",
    "                R_save[n] = R\n",
    "                N_moves_save[n] = i\n",
    "    \n",
    "                break\n",
    "\n",
    "            # IF THE EPISODE IS NOT OVER...\n",
    "            # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "            S=np.copy(S_next)\n",
    "            X=np.copy(X_next)\n",
    "            allowed_a=np.copy(allowed_a_next)\n",
    "\n",
    "            i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "\n",
    "        \n",
    "    return R_save, N_moves_save, Q_nn_A, Q_nn_B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a3d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_save2, N_moves_save2, Q_nn_A, Q_nn_B = DoubleQlearning(N_episodes= 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64134684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_save2_copy = R_save2.copy()\n",
    "\n",
    "plot_exponential_moving_avg(R_save2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1fff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.random()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
